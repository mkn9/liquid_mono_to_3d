"""
Efficiency Analysis Script

Analyzes efficiency metrics and generates performance charts.
"""

import json
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import argparse
from typing import Dict


def load_efficiency_metrics(metrics_file: Path) -> Dict:
    """
    Load efficiency metrics from file.
    
    Args:
        metrics_file: Path to JSON metrics file
    
    Returns:
        Dictionary of efficiency metrics
    """
    with open(metrics_file, 'r') as f:
        metrics = json.load(f)
    return metrics


def compute_efficiency_statistics(metrics: Dict) -> Dict:
    """
    Compute efficiency statistics.
    
    Args:
        metrics: Dictionary of raw efficiency metrics
    
    Returns:
        Dictionary of computed statistics
    """
    stats = {}
    
    # Compute savings percentage
    if 'avg_compute_per_track' in metrics:
        baseline_compute = 1.0  # Full processing
        actual_compute = metrics['avg_compute_per_track']
        stats['compute_savings_percent'] = (baseline_compute - actual_compute) / baseline_compute
    else:
        stats['compute_savings_percent'] = 0.0
    
    # Compute speedup
    if 'avg_decision_frame' in metrics:
        baseline_frames = 16  # Assuming 16 frame sequences
        actual_frames = metrics['avg_decision_frame']
        stats['avg_speedup'] = baseline_frames / actual_frames if actual_frames > 0 else 1.0
    else:
        stats['avg_speedup'] = 1.0
    
    # Copy relevant metrics
    for key in ['total_tracks', 'early_stop_rate', 'avg_decision_frame']:
        if key in metrics:
            stats[key] = metrics[key]
    
    return stats


def generate_efficiency_plots(metrics: Dict, output_dir: Path):
    """
    Generate efficiency plots.
    
    Args:
        metrics: Dictionary of efficiency metrics
        output_dir: Directory to save plots
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Plot 1: Decision Frame Histogram
    if 'decision_frames' in metrics:
        fig, ax = plt.subplots(figsize=(10, 6))
        
        decision_frames = metrics['decision_frames']
        ax.hist(decision_frames, bins=20, edgecolor='black', alpha=0.7)
        ax.axvline(np.mean(decision_frames), color='red', linestyle='--', 
                   label=f'Mean: {np.mean(decision_frames):.2f}', linewidth=2)
        
        ax.set_xlabel('Decision Frame', fontsize=12)
        ax.set_ylabel('Frequency', fontsize=12)
        ax.set_title('Distribution of Decision Frames', fontsize=14)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(output_dir / 'decision_frame_histogram.png', dpi=150)
        plt.close(fig)
    
    # Plot 2: Compute Usage Chart
    if 'compute_used' in metrics:
        fig, ax = plt.subplots(figsize=(10, 6))
        
        compute_used = metrics['compute_used']
        ax.hist(compute_used, bins=20, edgecolor='black', alpha=0.7, color='green')
        ax.axvline(np.mean(compute_used), color='red', linestyle='--',
                   label=f'Mean: {np.mean(compute_used):.2%}', linewidth=2)
        ax.axvline(1.0, color='orange', linestyle='--',
                   label='Baseline (100%)', linewidth=2)
        
        ax.set_xlabel('Compute Used (fraction of full)', fontsize=12)
        ax.set_ylabel('Frequency', fontsize=12)
        ax.set_title('Compute Usage Distribution', fontsize=14)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(output_dir / 'compute_usage_chart.png', dpi=150)
        plt.close(fig)


def create_efficiency_report(metrics: Dict, output_file: Path):
    """
    Create efficiency report.
    
    Args:
        metrics: Dictionary of efficiency metrics
        output_file: Path to output markdown file
    """
    output_file = Path(output_file)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    stats = compute_efficiency_statistics(metrics)
    
    report = f"""# Efficiency Report

## Summary Statistics

- **Total Tracks Processed**: {metrics.get('total_tracks', 'N/A')}
- **Average Decision Frame**: {metrics.get('avg_decision_frame', 'N/A'):.2f}
- **Early Stop Rate**: {metrics.get('early_stop_rate', 'N/A'):.2%}
- **Compute Savings**: {stats.get('compute_savings_percent', 0):.2%}
- **Average Speedup**: {stats.get('avg_speedup', 1):.2f}x
- **Total Compute Saved**: {metrics.get('total_compute_saved', 'N/A'):.1f}%

## Key Findings

### Early Stopping Performance
The early persistence classifier successfully identified transient tracks within the first
{metrics.get('avg_decision_frame', 4):.1f} frames on average, achieving an early stop rate of
{metrics.get('early_stop_rate', 0):.1%}.

### Computational Efficiency
By avoiding full processing of transient tracks, the system achieved:
- **{stats.get('compute_savings_percent', 0):.1%}** reduction in computation
- **{stats.get('avg_speedup', 1):.2f}x** speedup compared to baseline

### Resource Allocation
The compute gating mechanism successfully allocated minimal resources to transient tracks
while maintaining full processing for persistent tracks.

## Recommendations

1. **Further Optimization**: Consider reducing the early_stop_frame threshold to {int(metrics.get('avg_decision_frame', 4)) - 1}
   for even faster decisions.

2. **Confidence Tuning**: Current confidence threshold appears well-calibrated at 
   {metrics.get('confidence_threshold', 0.9):.2f}.

3. **Production Deployment**: The {stats.get('compute_savings_percent', 0):.1%} compute savings
   justifies deployment in production environments.

---
*Report generated automatically from efficiency metrics*
"""
    
    with open(output_file, 'w') as f:
        f.write(report)


def main():
    """Main efficiency analysis script."""
    parser = argparse.ArgumentParser(description='Analyze efficiency metrics')
    parser.add_argument('--metrics', type=str, required=True,
                       help='Path to efficiency metrics JSON file')
    parser.add_argument('--output', type=str, default='./analysis',
                       help='Output directory')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("EFFICIENCY ANALYSIS")
    print("=" * 80)
    print(f"Metrics file: {args.metrics}")
    print(f"Output: {args.output}")
    print("=" * 80)
    
    # Load metrics
    print("\nüìä Loading metrics...")
    metrics = load_efficiency_metrics(Path(args.metrics))
    print("‚úÖ Metrics loaded")
    
    # Compute statistics
    print("\nüî¢ Computing statistics...")
    stats = compute_efficiency_statistics(metrics)
    print("‚úÖ Statistics computed")
    
    # Generate plots
    print("\nüìà Generating plots...")
    generate_efficiency_plots(metrics, Path(args.output))
    print("‚úÖ Plots generated")
    
    # Create report
    print("\nüìù Creating report...")
    report_file = Path(args.output) / 'efficiency_report.md'
    create_efficiency_report(metrics, report_file)
    print(f"‚úÖ Report saved to: {report_file}")
    
    print("\n" + "=" * 80)
    print("ANALYSIS COMPLETE")
    print("=" * 80)
    print(f"\nKey Results:")
    print(f"  Compute Savings: {stats.get('compute_savings_percent', 0):.2%}")
    print(f"  Average Speedup: {stats.get('avg_speedup', 1):.2f}x")
    print(f"  Early Stop Rate: {metrics.get('early_stop_rate', 0):.2%}")
    print("=" * 80)


if __name__ == '__main__':
    main()

