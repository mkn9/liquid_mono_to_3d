2026-01-28 04:29:34,731 - INFO - HTTP Request: HEAD https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-01-28 04:29:34,734 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json "HTTP/1.1 200 OK"
`torch_dtype` is deprecated! Use `dtype` instead!

ðŸ”¬ Starting VLM Comparison Evaluation...

ðŸ”¬ Comparing TinyLlama vs GPT-4 on 3 samples...
ðŸ“¥ Loading TinyLlama: TinyLlama/TinyLlama-1.1B-Chat-v1.0
Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]Loading weights:   0%|          | 1/201 [00:00<00:00, 12595.51it/s, Materializing param=lm_head.weight]Loading weights:   0%|          | 1/201 [00:00<00:00, 6195.43it/s, Materializing param=lm_head.weight] Loading weights:   1%|          | 2/201 [00:00<00:04, 41.25it/s, Materializing param=model.embed_tokens.weight]Loading weights:   1%|          | 2/201 [00:00<00:04, 41.12it/s, Materializing param=model.embed_tokens.weight]Loading weights:   1%|â–         | 3/201 [00:00<00:03, 49.92it/s, Materializing param=model.layers.0.input_layernorm.weight]Loading weights:   1%|â–         | 3/201 [00:00<00:03, 49.77it/s, Materializing param=model.layers.0.input_layernorm.weight]Loading weights:   2%|â–         | 4/201 [00:00<00:02, 66.15it/s, Materializing param=model.layers.0.mlp.down_proj.weight]  Loading weights:   2%|â–         | 4/201 [00:00<00:02, 66.08it/s, Materializing param=model.layers.0.mlp.down_proj.weight]Loading weights:   2%|â–         | 5/201 [00:00<00:02, 82.43it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]Loading weights:   2%|â–         | 5/201 [00:00<00:02, 82.30it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]Loading weights:   3%|â–Ž         | 6/201 [00:00<00:01, 98.57it/s, Materializing param=model.layers.0.mlp.up_proj.weight]  Loading weights:   3%|â–Ž         | 6/201 [00:00<00:01, 98.47it/s, Materializing param=model.layers.0.mlp.up_proj.weight]Loading weights:   3%|â–Ž         | 7/201 [00:00<00:01, 114.66it/s, Materializing param=model.layers.0.post_attention_layernorm.weight]Loading weights:   3%|â–Ž         | 7/201 [00:00<00:01, 114.55it/s, Materializing param=model.layers.0.post_attention_layernorm.weight]Loading weights:   4%|â–         | 8/201 [00:00<00:01, 130.67it/s, Materializing param=model.layers.0.self_attn.k_proj.weight]        Loading weights:   4%|â–         | 8/201 [00:00<00:01, 130.55it/s, Materializing param=model.layers.0.self_attn.k_proj.weight]Loading weights:   4%|â–         | 9/201 [00:00<00:01, 146.60it/s, Materializing param=model.layers.0.self_attn.o_proj.weight]Loading weights:   4%|â–         | 9/201 [00:00<00:01, 146.41it/s, Materializing param=model.layers.0.self_attn.o_proj.weight]Loading weights:   5%|â–         | 10/201 [00:00<00:01, 162.38it/s, Materializing param=model.layers.0.self_attn.q_proj.weight]Loading weights:   5%|â–         | 10/201 [00:00<00:01, 162.22it/s, Materializing param=model.layers.0.self_attn.q_proj.weight]Loading weights:   5%|â–Œ         | 11/201 [00:00<00:01, 178.04it/s, Materializing param=model.layers.0.self_attn.v_proj.weight]Loading weights:   5%|â–Œ         | 11/201 [00:00<00:01, 177.86it/s, Materializing param=model.layers.0.self_attn.v_proj.weight]Loading weights:   6%|â–Œ         | 12/201 [00:00<00:00, 193.69it/s, Materializing param=model.layers.1.input_layernorm.weight] Loading weights:   6%|â–Œ         | 12/201 [00:00<00:00, 193.50it/s, Materializing param=model.layers.1.input_layernorm.weight]Loading weights:   6%|â–‹         | 13/201 [00:00<00:00, 209.26it/s, Materializing param=model.layers.1.mlp.down_proj.weight]  Loading weights:   6%|â–‹         | 13/201 [00:00<00:00, 209.06it/s, Materializing param=model.layers.1.mlp.down_proj.weight]Loading weights:   7%|â–‹         | 14/201 [00:00<00:00, 224.73it/s, Materializing param=model.layers.1.mlp.gate_proj.weight]Loading weights:   7%|â–‹         | 14/201 [00:00<00:00, 224.52it/s, Materializing param=model.layers.1.mlp.gate_proj.weight]Loading weights:   7%|â–‹         | 15/201 [00:00<00:00, 240.13it/s, Materializing param=model.layers.1.mlp.up_proj.weight]  Loading weights:   7%|â–‹         | 15/201 [00:00<00:00, 239.90it/s, Materializing param=model.layers.1.mlp.up_proj.weight]Loading weights:   8%|â–Š         | 16/201 [00:00<00:00, 212.63it/s, Materializing param=model.layers.1.post_attention_layernorm.weight]Loading weights:   8%|â–Š         | 16/201 [00:00<00:00, 212.22it/s, Materializing param=model.layers.1.post_attention_layernorm.weight]Loading weights:   8%|â–Š         | 17/201 [00:00<00:00, 225.11it/s, Materializing param=model.layers.1.self_attn.k_proj.weight]        Loading weights:   8%|â–Š         | 17/201 [00:00<00:00, 224.93it/s, Materializing param=model.layers.1.self_attn.k_proj.weight]Loading weights:   9%|â–‰         | 18/201 [00:00<00:00, 237.72it/s, Materializing param=model.layers.1.self_attn.o_proj.weight]Loading weights:   9%|â–‰         | 18/201 [00:00<00:00, 237.52it/s, Materializing param=model.layers.1.self_attn.o_proj.weight]Loading weights:   9%|â–‰         | 19/201 [00:00<00:00, 250.35it/s, Materializing param=model.layers.1.self_attn.q_proj.weight]Loading weights:   9%|â–‰         | 19/201 [00:00<00:00, 250.14it/s, Materializing param=model.layers.1.self_attn.q_proj.weight]Loading weights:  10%|â–‰         | 20/201 [00:00<00:00, 262.92it/s, Materializing param=model.layers.1.self_attn.v_proj.weight]Loading weights:  10%|â–‰         | 20/201 [00:00<00:00, 262.71it/s, Materializing param=model.layers.1.self_attn.v_proj.weight]Loading weights:  10%|â–ˆ         | 21/201 [00:00<00:00, 275.45it/s, Materializing param=model.layers.2.input_layernorm.weight] Loading weights:  10%|â–ˆ         | 21/201 [00:00<00:00, 275.24it/s, Materializing param=model.layers.2.input_layernorm.weight]Loading weights:  11%|â–ˆ         | 22/201 [00:00<00:00, 287.93it/s, Materializing param=model.layers.2.mlp.down_proj.weight]  Loading weights:  11%|â–ˆ         | 22/201 [00:00<00:00, 287.71it/s, Materializing param=model.layers.2.mlp.down_proj.weight]Loading weights:  11%|â–ˆâ–        | 23/201 [00:00<00:00, 285.35it/s, Materializing param=model.layers.2.mlp.gate_proj.weight]Loading weights:  11%|â–ˆâ–        | 23/201 [00:00<00:00, 284.78it/s, Materializing param=model.layers.2.mlp.gate_proj.weight]Loading weights:  12%|â–ˆâ–        | 24/201 [00:00<00:00, 291.21it/s, Materializing param=model.layers.2.mlp.up_proj.weight]  Loading weights:  12%|â–ˆâ–        | 24/201 [00:00<00:00, 290.53it/s, Materializing param=model.layers.2.mlp.up_proj.weight]Loading weights:  12%|â–ˆâ–        | 25/201 [00:00<00:00, 296.79it/s, Materializing param=model.layers.2.post_attention_layernorm.weight]Loading weights:  12%|â–ˆâ–        | 25/201 [00:00<00:00, 296.12it/s, Materializing param=model.layers.2.post_attention_layernorm.weight]Loading weights:  13%|â–ˆâ–Ž        | 26/201 [00:00<00:00, 307.41it/s, Materializing param=model.layers.2.self_attn.k_proj.weight]        Loading weights:  13%|â–ˆâ–Ž        | 26/201 [00:00<00:00, 307.10it/s, Materializing param=model.layers.2.self_attn.k_proj.weight]Loading weights:  13%|â–ˆâ–Ž        | 27/201 [00:00<00:00, 318.30it/s, Materializing param=model.layers.2.self_attn.o_proj.weight]Loading weights:  13%|â–ˆâ–Ž        | 27/201 [00:00<00:00, 317.97it/s, Materializing param=model.layers.2.self_attn.o_proj.weight]Loading weights:  14%|â–ˆâ–        | 28/201 [00:00<00:00, 328.85it/s, Materializing param=model.layers.2.self_attn.q_proj.weight]Loading weights:  14%|â–ˆâ–        | 28/201 [00:00<00:00, 328.52it/s, Materializing param=model.layers.2.self_attn.q_proj.weight]Loading weights:  14%|â–ˆâ–        | 29/201 [00:00<00:00, 337.57it/s, Materializing param=model.layers.2.self_attn.v_proj.weight]Loading weights:  14%|â–ˆâ–        | 29/201 [00:00<00:00, 336.54it/s, Materializing param=model.layers.2.self_attn.v_proj.weight]Loading weights:  15%|â–ˆâ–        | 30/201 [00:00<00:00, 347.61it/s, Materializing param=model.layers.3.input_layernorm.weight] Loading weights:  15%|â–ˆâ–        | 30/201 [00:00<00:00, 347.36it/s, Materializing param=model.layers.3.input_layernorm.weight]Loading weights:  15%|â–ˆâ–Œ        | 31/201 [00:00<00:00, 341.67it/s, Materializing param=model.layers.3.mlp.down_proj.weight]  Loading weights:  15%|â–ˆâ–Œ        | 31/201 [00:00<00:00, 341.10it/s, Materializing param=model.layers.3.mlp.down_proj.weight]Loading weights:  16%|â–ˆâ–Œ        | 32/201 [00:00<00:00, 326.29it/s, Materializing param=model.layers.3.mlp.gate_proj.weight]Loading weights:  16%|â–ˆâ–Œ        | 32/201 [00:00<00:00, 325.81it/s, Materializing param=model.layers.3.mlp.gate_proj.weight]Loading weights:  16%|â–ˆâ–‹        | 33/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.3.mlp.gate_proj.weight]Loading weights:  16%|â–ˆâ–‹        | 33/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.3.mlp.up_proj.weight]  Loading weights:  16%|â–ˆâ–‹        | 33/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.3.mlp.up_proj.weight]Loading weights:  17%|â–ˆâ–‹        | 34/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.3.post_attention_layernorm.weight]Loading weights:  17%|â–ˆâ–‹        | 34/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.3.post_attention_layernorm.weight]Loading weights:  17%|â–ˆâ–‹        | 35/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.3.self_attn.k_proj.weight]        Loading weights:  17%|â–ˆâ–‹        | 35/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.3.self_attn.k_proj.weight]Loading weights:  18%|â–ˆâ–Š        | 36/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.3.self_attn.o_proj.weight]Loading weights:  18%|â–ˆâ–Š        | 36/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.3.self_attn.o_proj.weight]Loading weights:  18%|â–ˆâ–Š        | 37/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.3.self_attn.q_proj.weight]Loading weights:  18%|â–ˆâ–Š        | 37/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.3.self_attn.q_proj.weight]Loading weights:  19%|â–ˆâ–‰        | 38/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.3.self_attn.v_proj.weight]Loading weights:  19%|â–ˆâ–‰        | 38/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.3.self_attn.v_proj.weight]Loading weights:  19%|â–ˆâ–‰        | 39/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.input_layernorm.weight] Loading weights:  19%|â–ˆâ–‰        | 39/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.input_layernorm.weight]Loading weights:  20%|â–ˆâ–‰        | 40/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.mlp.down_proj.weight]  Loading weights:  20%|â–ˆâ–‰        | 40/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.mlp.down_proj.weight]Loading weights:  20%|â–ˆâ–ˆ        | 41/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.mlp.gate_proj.weight]Loading weights:  20%|â–ˆâ–ˆ        | 41/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.mlp.gate_proj.weight]Loading weights:  21%|â–ˆâ–ˆ        | 42/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.mlp.up_proj.weight]  Loading weights:  21%|â–ˆâ–ˆ        | 42/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.mlp.up_proj.weight]Loading weights:  21%|â–ˆâ–ˆâ–       | 43/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.post_attention_layernorm.weight]Loading weights:  21%|â–ˆâ–ˆâ–       | 43/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.post_attention_layernorm.weight]Loading weights:  22%|â–ˆâ–ˆâ–       | 44/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.self_attn.k_proj.weight]        Loading weights:  22%|â–ˆâ–ˆâ–       | 44/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.self_attn.k_proj.weight]Loading weights:  22%|â–ˆâ–ˆâ–       | 45/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.self_attn.o_proj.weight]Loading weights:  22%|â–ˆâ–ˆâ–       | 45/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.self_attn.o_proj.weight]Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 46/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.self_attn.q_proj.weight]Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 46/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.self_attn.q_proj.weight]Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 47/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.self_attn.v_proj.weight]Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 47/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.4.self_attn.v_proj.weight]Loading weights:  24%|â–ˆâ–ˆâ–       | 48/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.input_layernorm.weight] Loading weights:  24%|â–ˆâ–ˆâ–       | 48/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.input_layernorm.weight]Loading weights:  24%|â–ˆâ–ˆâ–       | 49/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.mlp.down_proj.weight]  Loading weights:  24%|â–ˆâ–ˆâ–       | 49/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.mlp.down_proj.weight]Loading weights:  25%|â–ˆâ–ˆâ–       | 50/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.mlp.gate_proj.weight]Loading weights:  25%|â–ˆâ–ˆâ–       | 50/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.mlp.gate_proj.weight]Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 51/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.mlp.up_proj.weight]  Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 51/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.mlp.up_proj.weight]Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 52/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.post_attention_layernorm.weight]Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 52/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.post_attention_layernorm.weight]Loading weights:  26%|â–ˆâ–ˆâ–‹       | 53/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.self_attn.k_proj.weight]        Loading weights:  26%|â–ˆâ–ˆâ–‹       | 53/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.self_attn.k_proj.weight]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 54/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.self_attn.o_proj.weight]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 54/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.self_attn.o_proj.weight]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 55/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.self_attn.q_proj.weight]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 55/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.self_attn.q_proj.weight]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 56/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.self_attn.v_proj.weight]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 56/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.5.self_attn.v_proj.weight]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 57/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.input_layernorm.weight] Loading weights:  28%|â–ˆâ–ˆâ–Š       | 57/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.input_layernorm.weight]Loading weights:  29%|â–ˆâ–ˆâ–‰       | 58/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.mlp.down_proj.weight]  Loading weights:  29%|â–ˆâ–ˆâ–‰       | 58/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.mlp.down_proj.weight]Loading weights:  29%|â–ˆâ–ˆâ–‰       | 59/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.mlp.gate_proj.weight]Loading weights:  29%|â–ˆâ–ˆâ–‰       | 59/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.mlp.gate_proj.weight]Loading weights:  30%|â–ˆâ–ˆâ–‰       | 60/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.mlp.up_proj.weight]  Loading weights:  30%|â–ˆâ–ˆâ–‰       | 60/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.mlp.up_proj.weight]Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 61/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.post_attention_layernorm.weight]Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 61/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.post_attention_layernorm.weight]Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 62/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.self_attn.k_proj.weight]        Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 62/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.self_attn.k_proj.weight]Loading weights:  31%|â–ˆâ–ˆâ–ˆâ–      | 63/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.self_attn.o_proj.weight]Loading weights:  31%|â–ˆâ–ˆâ–ˆâ–      | 63/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.self_attn.o_proj.weight]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 64/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.self_attn.q_proj.weight]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 64/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.self_attn.q_proj.weight]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 65/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.self_attn.v_proj.weight]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 65/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.6.self_attn.v_proj.weight]Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.input_layernorm.weight] Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.input_layernorm.weight]Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.mlp.down_proj.weight]  Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.mlp.down_proj.weight]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 68/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.mlp.gate_proj.weight]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 68/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.mlp.gate_proj.weight]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 69/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.mlp.up_proj.weight]  Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 69/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.mlp.up_proj.weight]Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 70/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.post_attention_layernorm.weight]Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 70/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.post_attention_layernorm.weight]Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.self_attn.k_proj.weight]        Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.self_attn.k_proj.weight]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.self_attn.o_proj.weight]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.self_attn.o_proj.weight]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.self_attn.q_proj.weight]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.self_attn.q_proj.weight]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.self_attn.v_proj.weight]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.7.self_attn.v_proj.weight]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 75/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.input_layernorm.weight] Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 75/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.input_layernorm.weight]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.mlp.down_proj.weight]  Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.mlp.down_proj.weight]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.mlp.gate_proj.weight]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.mlp.gate_proj.weight]Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.mlp.up_proj.weight]  Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.mlp.up_proj.weight]Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 79/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.post_attention_layernorm.weight]Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 79/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.post_attention_layernorm.weight]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 80/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.self_attn.k_proj.weight]        Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 80/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.self_attn.k_proj.weight]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.self_attn.o_proj.weight]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.self_attn.o_proj.weight]Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.self_attn.q_proj.weight]Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.self_attn.q_proj.weight]Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.self_attn.v_proj.weight]Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.8.self_attn.v_proj.weight]Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.9.input_layernorm.weight] Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.9.input_layernorm.weight]Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 85/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.9.mlp.down_proj.weight]  Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 85/201 [00:00<00:00, 323.75it/s, Materializing param=model.layers.9.mlp.down_proj.weight]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.mlp.down_proj.weight]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.mlp.gate_proj.weight]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.mlp.gate_proj.weight]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.mlp.up_proj.weight]  Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.mlp.up_proj.weight]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.post_attention_layernorm.weight]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.post_attention_layernorm.weight]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.self_attn.k_proj.weight]        Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.self_attn.k_proj.weight]Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 90/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.self_attn.o_proj.weight]Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 90/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.self_attn.o_proj.weight]Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.self_attn.q_proj.weight]Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.self_attn.q_proj.weight]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.self_attn.v_proj.weight]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.9.self_attn.v_proj.weight]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.input_layernorm.weight]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.input_layernorm.weight]Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.mlp.down_proj.weight]  Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.mlp.down_proj.weight]Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 95/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.mlp.gate_proj.weight]Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 95/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.mlp.gate_proj.weight]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.mlp.up_proj.weight]  Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.mlp.up_proj.weight]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.post_attention_layernorm.weight]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.post_attention_layernorm.weight]Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.self_attn.k_proj.weight]        Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.self_attn.k_proj.weight]Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.self_attn.o_proj.weight]Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.self_attn.o_proj.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 100/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.self_attn.q_proj.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 100/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.self_attn.q_proj.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.self_attn.v_proj.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.10.self_attn.v_proj.weight]Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.input_layernorm.weight] Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.input_layernorm.weight]Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 103/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.mlp.down_proj.weight]  Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 103/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.mlp.down_proj.weight]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.mlp.gate_proj.weight]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.mlp.gate_proj.weight]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 105/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.mlp.up_proj.weight]  Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 105/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.mlp.up_proj.weight]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.post_attention_layernorm.weight]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.post_attention_layernorm.weight]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.self_attn.k_proj.weight]        Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.self_attn.k_proj.weight]Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 108/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.self_attn.o_proj.weight]Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 108/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.self_attn.o_proj.weight]Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.self_attn.q_proj.weight]Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.self_attn.q_proj.weight]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 110/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.self_attn.v_proj.weight]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 110/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.11.self_attn.v_proj.weight]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.input_layernorm.weight] Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.input_layernorm.weight]Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.mlp.down_proj.weight]  Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.mlp.down_proj.weight]Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 113/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.mlp.gate_proj.weight]Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 113/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.mlp.gate_proj.weight]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.mlp.up_proj.weight]  Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.mlp.up_proj.weight]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 115/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.post_attention_layernorm.weight]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 115/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.post_attention_layernorm.weight]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.self_attn.k_proj.weight]        Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.self_attn.k_proj.weight]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.self_attn.o_proj.weight]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.self_attn.o_proj.weight]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 118/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.self_attn.q_proj.weight]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 118/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.self_attn.q_proj.weight]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.self_attn.v_proj.weight]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.12.self_attn.v_proj.weight]Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 120/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.input_layernorm.weight] Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 120/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.input_layernorm.weight]Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.mlp.down_proj.weight]  Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.mlp.down_proj.weight]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.mlp.gate_proj.weight]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.mlp.gate_proj.weight]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 123/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.mlp.up_proj.weight]  Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 123/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.mlp.up_proj.weight]Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.post_attention_layernorm.weight]Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.post_attention_layernorm.weight]Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 125/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.self_attn.k_proj.weight]        Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 125/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.self_attn.k_proj.weight]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.self_attn.o_proj.weight]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.self_attn.o_proj.weight]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.self_attn.q_proj.weight]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.self_attn.q_proj.weight]Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 128/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.self_attn.v_proj.weight]Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 128/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.13.self_attn.v_proj.weight]Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.input_layernorm.weight] Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.input_layernorm.weight]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 130/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.mlp.down_proj.weight]  Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 130/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.mlp.down_proj.weight]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.mlp.gate_proj.weight]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.mlp.gate_proj.weight]Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.mlp.up_proj.weight]  Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.mlp.up_proj.weight]Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 133/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.post_attention_layernorm.weight]Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 133/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.post_attention_layernorm.weight]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.self_attn.k_proj.weight]        Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.self_attn.k_proj.weight]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 135/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.self_attn.o_proj.weight]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 135/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.self_attn.o_proj.weight]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.self_attn.q_proj.weight]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.self_attn.q_proj.weight]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.self_attn.v_proj.weight]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/201 [00:00<00:00, 430.91it/s, Materializing param=model.layers.14.self_attn.v_proj.weight]Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 138/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.14.self_attn.v_proj.weight]Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 138/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.input_layernorm.weight] Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 138/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.input_layernorm.weight]Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.mlp.down_proj.weight]  Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.mlp.down_proj.weight]Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 140/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.mlp.gate_proj.weight]Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 140/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.mlp.gate_proj.weight]Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.mlp.up_proj.weight]  Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.mlp.up_proj.weight]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.post_attention_layernorm.weight]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.post_attention_layernorm.weight]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 143/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.self_attn.k_proj.weight]        Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 143/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.self_attn.k_proj.weight]Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.self_attn.o_proj.weight]Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.self_attn.o_proj.weight]Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 145/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.self_attn.q_proj.weight]Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 145/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.self_attn.q_proj.weight]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.self_attn.v_proj.weight]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.15.self_attn.v_proj.weight]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.input_layernorm.weight] Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.input_layernorm.weight]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 148/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.mlp.down_proj.weight]  Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 148/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.mlp.down_proj.weight]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.mlp.gate_proj.weight]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.mlp.gate_proj.weight]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 150/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.mlp.up_proj.weight]  Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 150/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.mlp.up_proj.weight]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.post_attention_layernorm.weight]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.post_attention_layernorm.weight]Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.self_attn.k_proj.weight]        Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.self_attn.k_proj.weight]Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 153/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.self_attn.o_proj.weight]Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 153/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.self_attn.o_proj.weight]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.self_attn.q_proj.weight]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.self_attn.q_proj.weight]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 155/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.self_attn.v_proj.weight]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 155/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.16.self_attn.v_proj.weight]Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.input_layernorm.weight] Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.input_layernorm.weight]Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.mlp.down_proj.weight]  Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.mlp.down_proj.weight]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 158/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.mlp.gate_proj.weight]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 158/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.mlp.gate_proj.weight]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.mlp.up_proj.weight]  Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.mlp.up_proj.weight]Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 160/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.post_attention_layernorm.weight]Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 160/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.post_attention_layernorm.weight]Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.self_attn.k_proj.weight]        Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.self_attn.k_proj.weight]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.self_attn.o_proj.weight]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.self_attn.o_proj.weight]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 163/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.self_attn.q_proj.weight]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 163/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.self_attn.q_proj.weight]Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.self_attn.v_proj.weight]Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.17.self_attn.v_proj.weight]Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 165/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.input_layernorm.weight] Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 165/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.input_layernorm.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.mlp.down_proj.weight]  Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.mlp.down_proj.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.mlp.gate_proj.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.mlp.gate_proj.weight]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 168/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.mlp.up_proj.weight]  Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 168/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.mlp.up_proj.weight]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.post_attention_layernorm.weight]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.post_attention_layernorm.weight]Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 170/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.self_attn.k_proj.weight]        Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 170/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.self_attn.k_proj.weight]Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.self_attn.o_proj.weight]Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.self_attn.o_proj.weight]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.self_attn.q_proj.weight]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.self_attn.q_proj.weight]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 173/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.self_attn.v_proj.weight]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 173/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.18.self_attn.v_proj.weight]Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.input_layernorm.weight] Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.input_layernorm.weight]Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 175/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.mlp.down_proj.weight]  Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 175/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.mlp.down_proj.weight]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.mlp.gate_proj.weight]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.mlp.gate_proj.weight]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.mlp.up_proj.weight]  Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.mlp.up_proj.weight]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 178/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.post_attention_layernorm.weight]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 178/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.post_attention_layernorm.weight]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.self_attn.k_proj.weight]        Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.self_attn.k_proj.weight]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 180/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.self_attn.o_proj.weight]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 180/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.self_attn.o_proj.weight]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.self_attn.q_proj.weight]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.self_attn.q_proj.weight]Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.self_attn.v_proj.weight]Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.19.self_attn.v_proj.weight]Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 183/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.20.input_layernorm.weight] Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 183/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.20.input_layernorm.weight]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.20.mlp.down_proj.weight]  Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.20.mlp.down_proj.weight]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 185/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.20.mlp.gate_proj.weight]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 185/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.20.mlp.gate_proj.weight]Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.20.mlp.up_proj.weight]  Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.20.mlp.up_proj.weight]Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.20.post_attention_layernorm.weight]Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.20.post_attention_layernorm.weight]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 188/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.20.self_attn.k_proj.weight]        Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 188/201 [00:00<00:00, 469.28it/s, Materializing param=model.layers.20.self_attn.k_proj.weight]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.20.self_attn.k_proj.weight]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.20.self_attn.o_proj.weight]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.20.self_attn.o_proj.weight]Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 190/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.20.self_attn.q_proj.weight]Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 190/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.20.self_attn.q_proj.weight]Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.20.self_attn.v_proj.weight]Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.20.self_attn.v_proj.weight]Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.input_layernorm.weight] Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.input_layernorm.weight]Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 193/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.mlp.down_proj.weight]  Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 193/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.mlp.down_proj.weight]Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.mlp.gate_proj.weight]Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.mlp.gate_proj.weight]Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 195/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.mlp.up_proj.weight]  Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 195/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.mlp.up_proj.weight]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.post_attention_layernorm.weight]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.post_attention_layernorm.weight]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.self_attn.k_proj.weight]        Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.self_attn.k_proj.weight]Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 198/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.self_attn.o_proj.weight]Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 198/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.self_attn.o_proj.weight]Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.self_attn.q_proj.weight]Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.self_attn.q_proj.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 200/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.self_attn.v_proj.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 200/201 [00:00<00:00, 484.50it/s, Materializing param=model.layers.21.self_attn.v_proj.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:00<00:00, 484.50it/s, Materializing param=model.norm.weight]                      Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:00<00:00, 484.50it/s, Materializing param=model.norm.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:00<00:00, 470.62it/s, Materializing param=model.norm.weight]
2026-01-28 04:29:35,721 - INFO - HTTP Request: HEAD https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/generation_config.json "HTTP/1.1 307 Temporary Redirect"
2026-01-28 04:29:35,725 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/generation_config.json "HTTP/1.1 200 OK"
2026-01-28 04:29:35,751 - INFO - HTTP Request: HEAD https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-01-28 04:29:35,755 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json "HTTP/1.1 200 OK"
2026-01-28 04:29:35,770 - INFO - HTTP Request: HEAD https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-01-28 04:29:35,774 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json "HTTP/1.1 200 OK"
2026-01-28 04:29:35,789 - INFO - HTTP Request: HEAD https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-01-28 04:29:35,792 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json "HTTP/1.1 200 OK"
2026-01-28 04:29:35,808 - INFO - HTTP Request: GET https://huggingface.co/api/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-01-28 04:29:35,827 - INFO - HTTP Request: GET https://huggingface.co/api/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-01-28 04:29:36,072 - INFO - Setting up cameras
2026-01-28 04:29:36,072 - INFO - Camera 1 position: [0.  0.  2.5]
2026-01-28 04:29:36,072 - INFO - Camera 2 position: [1.  0.  2.5]
2026-01-28 04:29:36,072 - INFO - Setting up cameras
2026-01-28 04:29:36,073 - INFO - Camera 1 position: [0.  0.  2.5]
2026-01-28 04:29:36,073 - INFO - Camera 2 position: [1.  0.  2.5]
2026-01-28 04:29:36,111 - INFO - Setting up cameras
2026-01-28 04:29:36,112 - INFO - Camera 1 position: [0.  0.  2.5]
2026-01-28 04:29:36,112 - INFO - Camera 2 position: [1.  0.  2.5]
2026-01-28 04:29:40,066 - INFO - Setting up cameras
2026-01-28 04:29:40,066 - INFO - Camera 1 position: [0.  0.  2.5]
2026-01-28 04:29:40,067 - INFO - Camera 2 position: [1.  0.  2.5]
2026-01-28 04:29:40,067 - INFO - Setting up cameras
2026-01-28 04:29:40,067 - INFO - Camera 1 position: [0.  0.  2.5]
2026-01-28 04:29:40,067 - INFO - Camera 2 position: [1.  0.  2.5]
2026-01-28 04:29:40,113 - INFO - Setting up cameras
2026-01-28 04:29:40,114 - INFO - Camera 1 position: [0.  0.  2.5]
2026-01-28 04:29:40,114 - INFO - Camera 2 position: [1.  0.  2.5]
2026-01-28 04:29:43,369 - INFO - Setting up cameras
2026-01-28 04:29:43,369 - INFO - Camera 1 position: [0.  0.  2.5]
2026-01-28 04:29:43,370 - INFO - Camera 2 position: [1.  0.  2.5]
2026-01-28 04:29:43,370 - INFO - Setting up cameras
2026-01-28 04:29:43,370 - INFO - Camera 1 position: [0.  0.  2.5]
2026-01-28 04:29:43,370 - INFO - Camera 2 position: [1.  0.  2.5]
2026-01-28 04:29:43,405 - INFO - Setting up cameras
2026-01-28 04:29:43,406 - INFO - Camera 1 position: [0.  0.  2.5]
2026-01-28 04:29:43,406 - INFO - Camera 2 position: [1.  0.  2.5]
âœ… TinyLlama loaded on cuda:0
âš ï¸  OPENAI_API_KEY not set, using placeholder

Sample 1/3:
ðŸ“¥ Loading MagVIT model from: /home/ubuntu/liquid_mono_to_3d/experiments/liquid_vlm_integration/checkpoints/magvit_100pct_20260125.pt
âœ… MagVIT model loaded successfully
   Device: cuda
   Native feature dim: 256
   Projected to: 512 (Liquid Fusion compatible)
  TinyLlama: 

In this case, the trajectory is a straight line with a slope of -1. The initia...
  GPT-4: [GPT-4 Placeholder] A trajectory with embeddings of shape torch.Size([1, 4096])...

Sample 2/3:
ðŸ“¥ Loading MagVIT model from: /home/ubuntu/liquid_mono_to_3d/experiments/liquid_vlm_integration/checkpoints/magvit_100pct_20260125.pt
âœ… MagVIT model loaded successfully
   Device: cuda
   Native feature dim: 256
   Projected to: 512 (Liquid Fusion compatible)
  TinyLlama: 

In this case, the trajectory is a straight line with a slope of -1. This means...
  GPT-4: [GPT-4 Placeholder] A trajectory with embeddings of shape torch.Size([1, 4096])...

Sample 3/3:
ðŸ“¥ Loading MagVIT model from: /home/ubuntu/liquid_mono_to_3d/experiments/liquid_vlm_integration/checkpoints/magvit_100pct_20260125.pt
âœ… MagVIT model loaded successfully
   Device: cuda
   Native feature dim: 256
   Projected to: 512 (Liquid Fusion compatible)
  TinyLlama: 

In this case, the trajectory is a straight line with a slope of -1. This means...
  GPT-4: [GPT-4 Placeholder] A trajectory with embeddings of shape torch.Size([1, 4096])...

âœ… Results saved to: experiments/liquid_vlm_integration/results/20260128_0429_vlm_comparison.json

Sample output:
  TinyLlama: 

In this case, the trajectory is a straight line with a slope of -1. The initial point (0, 1) is th...
  GPT-4: [GPT-4 Placeholder] A trajectory with embeddings of shape torch.Size([1, 4096])...
